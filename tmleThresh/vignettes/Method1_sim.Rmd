---
title: "Method1_simulation"
output: html_document
---

```{r setup, include=FALSE}
#remotes::install_github("Larsvanderlaan/RStatisticalSoftware/tmleThresh")
devtools::document()
```


```{r}

remotes::install_github("Larsvanderlaan/tmle3", ref = "updating_updater")
```

```{r}
library(simcausal)
library(dplyr)


# variable: covariates W1,W2,W3. Immuresponse S. Disease Y. Sampling G.
## 3 cases for covariates: cov in {'non_covariate','non_confound','confound'}
## 4 models for P(Y|S,W): model in {'logit','probit','step','scale'}

# Examples:
## 1. non-covariate (model:'logit')
dat_logit<-simu(Risk=0.1,p0=1,p1=1,cov='non_covariate',model='logit') 
data1<-sim_thre(dat_logit,n = 1000,rndseed=1,p=c(0.01,0.03,0.05,0.07,0.09))
mean(data1$simmed_data$Y)

```

```{r}
library(simcausal)
D <- DAG.empty()
D <- D +
    node("W1", distr = "runif", min = -1, max = 1) +
    node("W2", distr = "rnorm", mean = 0) +
    node("W3full", distr = "rexp", rate = 1) +
  node("W3", distr = "rconst", const = min(W3full, 3)) +
  node("Sfull", distr = "rgamma", shape = abs(2 + W3full + W3full*W2 + W2*exp(W1) + cos(W2) + sin(W1))  ) +
    node("S", distr = "rconst", const = min(Sfull, 13)/13) +
  node("pY", distr = "rconst", const = plogis(-5 + exp(S) + W1*(W2 >0) - W2*(W1>0) + W3full * S - sin(W2) + cos(W1))) +
  node("Y", distr = "rbinom", size =1, prob = pY)


D <- set.DAG(D)
dat <- sim(D,n =1000)
dat
hist(dat$S)
table(dat$Y)
vs <- c(0, 0.1, 0.3, 0.5, 0.8)
for(v in vs) {
  print(sum(dat$Y * (dat$S>=v)) / sum(dat$S >=v))
}

D <- DAG.empty()
D <- D +
    node("W1", distr = "runif", min = -1, max = 1) +
    node("W2", distr = "rnorm", mean = 0) +
    node("W3full", distr = "rexp", rate = 1) +
  node("W3", distr = "rconst", const = min(W3full, 3)) +
  node("Sfull", distr = "rgamma", shape = abs(2.5)  ) +
    node("S", distr = "rconst", const = min(Sfull, 8)/8) +
  node("pY", distr = "rconst", const = plogis(-2 + 4*S + W1*(W2 >0) - W2*(W1>0) + W3full * S - sin(W2) + cos(W1))) +
  node("Y", distr = "rbinom", size =1, prob = pY)


D <- set.DAG(D)
dat <- sim(D,n =1000)
dat
hist(dat$S)
table(dat$Y)
vs <- c(0, 0.1, 0.3, 0.5, 0.8)
for(v in vs) {
  print(sum(dat$Y * (dat$S>=v)) / sum(dat$S >=v))
}
```








```{r}
data <- dat
data
data$weights <- 1
library(tmle3)
#lrnr <- Lrnr_pooled_hazards$new(Lrnr_xgboost$new())
lrnr_Y <- Lrnr_xgboost$new()
lrnr_A <- Lrnr_xgboost$new()

tmle_spec <- tmle3_Spec_Threshold$new(method = "Psi_W")

learner_list <- list("A" = lrnr_A, "Y" =lrnr_Y)
node_list <- list("W" = c("W1", "W2", "W3"), "A" = "S", "Y" = "Y", weights = "weights")

start_time <- proc.time()

  tmle_task <- tmle_spec$make_tmle_task(data, node_list)
  task_time <- proc.time()

  initial_likelihood <- tmle_spec$make_initial_likelihood(tmle_task, learner_list)
  likelihood_time <- proc.time()

  updater <- tmle_spec$make_updater(maxit = 100, verbose = T)
  targeted_likelihood <- tmle_spec$make_targeted_likelihood(initial_likelihood, updater)

  tmle_params <- tmle_spec$make_params(tmle_task, targeted_likelihood)
  
```

```{r}
suppressWarnings(targeted_likelihood$updater$update_step(targeted_likelihood, tmle_task))
```


```{r}
estimates <- tmle_params[[1]]$estimates(tmle_task)
# This should be very small
colMeans(estimates$IC)
# Estimates of Psi
estimates$psi

# Estimates and confidence bounds
summary_from_estimates(tmle_task, list(estimates))
```












```{r}
threshold_function = function(A) {as.vector(quantile(A, seq(0.1, 0.90, length.out = 10)))}
vs <- threshold_function(fit$tmle_task$get_tmle_node("A"))
for(v in vs) {
  num = sum(data$Y * (data$S >= v) * data$weights )
denom = sum((data$S >= v) * data$weights )
print(num/denom)

  
  
}


```


