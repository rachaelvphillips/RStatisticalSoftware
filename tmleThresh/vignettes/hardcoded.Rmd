---
title: "Untitled"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
 n=100000
library(simcausal)
sim_data <- function(n, bias = F) {
bound <- Vectorize(tmle3::bound)
D <- DAG.empty()
D <- D +
  node("Wcont", distr = "runif", min = -1 , max = 1) +
   node("W", distr = "rconst", const = round(Wcont, 1)/1) +
  node("Wcont2", distr = "runif", min = -1 , max = 1) +
   node("W2", distr = "rconst", const = round(Wcont, 1)/1) +
  node("g1", distr = "rconst", const =   bound(plogis(W + W2 - W * W2), 0.08)) +
  node("A", distr = "rbinom", size = 1,  prob = g1) +
    node("EY", distr = "rconst", const = plogis(W/2 + W2/2 + A/2 + 0.5* A*W/2 - 0.5* A*W2/2)) +
  node("Y", distr = "rbinom", size =1 , prob = EY) +

  node ("EY1", distr = "rconst",  const = plogis(W/2 + W2/2 + 1/2 + 0.5* 1*W/2 - 0.5* 1*W2/2))
setD <- set.DAG(D, vecfun = c("bound"))
data <- sim(setD, n = n)
data <- as.data.table(data)
data
}
data <- sim_data(n , F)
mean(data$EY1)
```

```{r}
  transform_data = function(data, node_list) {
      T_tilde_name <- node_list$T_tilde
      Delta_name <- node_list$Delta
      T_tilde_data <- data[T_tilde_name]
      Delta_data <- data[Delta_name]
      k_grid <- 1:max(T_tilde_data)

      if (is.null(node_list$id)) {
        id <- 1:nrow(data)
        data <- cbind(id = id, data)
        node_list$id <- "id"
      }

      all_times <- lapply(k_grid, function(t_current) {
        df_time <- copy(data)
        # TODO: check
        df_time$N <- as.numeric(t_current == T_tilde_data & Delta_data == 1)
        df_time$A_c <- as.numeric(t_current == T_tilde_data & Delta_data == 0)
        df_time$pre_failure <- as.numeric(t_current <= T_tilde_data)
        df_time$t <- t_current
        return(df_time)
      })
      df_long <- rbindlist(all_times)

      long_node_list <- copy(node_list)
      long_node_list$time <- "t"
      long_node_list$N <- "N"
      long_node_list$A_c <- "A_c"
      long_node_list$pre_failure <- "pre_failure"

      return(list(long_data = df_long, long_node_list = long_node_list))
    }

```

```{r}
library(kyotil)
dat.mock=read.csv("https://raw.githubusercontent.com/youyifong/CovidCorrSAP/master/data_processing/COVID_VEtrial_practicedata_longerterm.csv?token=ACHPI4YSDNVFB5OVVSVOTTS7TCFMW")

names(dat.mock)[1]="Ptid"
times=c("B","Day57")
assays=c("bindSpike","bindRBD","pseudoneut","liveneut")
markers=c(outer(times, assays, "%.%"))


dat.mock$age.geq.65=as.integer(dat.mock$Age>=65)


###########################################################################
# stratum and weights

# Bstratum, 1-8, defines the 8 baseline strata within trt/serostatus
dat.mock$Bstratum=1+strtoi(with(dat.mock, paste0(MinorityInd, HighRiskInd, as.integer(Age>=65))), base = 2)
# tps stratum, 1-32, used in tps regression
dat.mock$tps.stratum = 1+strtoi(with(dat.mock, paste0(Trt, Bserostatus, MinorityInd, HighRiskInd, as.integer(Age>=65))), base = 2)
# Wstratum, 1-33. Differs from tps stratum in that case is a separate stratum. Used to compute sampling weights
dat.mock$Wstratum = ifelse(dat.mock$EventInd==1, 1+max(dat.mock$tps.stratum), dat.mock$tps.stratum) 

dat.mock$hasAllMarkers = complete.cases(dat.mock[markers])

with(dat.mock, table(Wstratum, hasAllMarkers, TwophasesampIndLongterm))

# compute inverse sampling prob weight, assuming that we will impute missing values for all in ph2
tmp=with(dat.mock, table(Wstratum, TwophasesampIndLongterm))
weights=rowSums(tmp)/tmp[,2]
dat.mock$wt=weights[dat.mock$Wstratum]

with(dat.mock, table(TwophasesampIndLongterm, Perprotocol))

dat.mock.ph2=subset(dat.mock, TwophasesampIndLongterm==1 & Perprotocol)
with(dat.mock.ph2, table(Wstratum, hasAllMarkers))
 

###########################################################################
# impute missing immune biomarkers in ph2
#     impute vaccine and placebo separately
#     use all assays
#     use baseline and D57, but not Delta

library(mice)
set.seed(1)
n.imp=10

for (.trt in 0:1) {
    imp=mice(dat.mock.ph2[dat.mock.ph2$Trt==.trt, markers],m=n.imp)
    # use the first imputation by default
    dat.mock.ph2[dat.mock.ph2$Trt==.trt, markers]=mice::complete(imp, action=1)
    # keep n.imp imputations
    for (i in 1:n.imp) dat.mock.ph2[dat.mock.ph2$Trt==.trt, markers%.%".imp"%.%i]=mice::complete(imp, action=i)
}
stopifnot(all(table(dat.mock.ph2$Wstratum, complete.cases(dat.mock.ph2[markers]))))

# populate dat.mock markers with the imputed values
dat.mock[markers]=dat.mock.ph2[markers][match(dat.mock$Ptid, dat.mock.ph2$Ptid),]
for (i in 1:n.imp) dat.mock[markers%.%".imp"%.%i]=dat.mock.ph2[markers%.%".imp"%.%i][match(dat.mock$Ptid, dat.mock.ph2$Ptid),]


###########################################################################
# define delta for both dat.mock and dat.mock.ph2

dat.mock    ["Delta"%.%assays]=dat.mock    ["Day57"%.%assays]-dat.mock    ["B"%.%assays]
dat.mock.ph2["Delta"%.%assays]=dat.mock.ph2["Day57"%.%assays]-dat.mock.ph2["B"%.%assays]
for (i in 1:n.imp) dat.mock    ["Delta"%.%assays%.%".imp"%.%i]=dat.mock    ["Day57"%.%assays%.%".imp"%.%i]-dat.mock    ["B"%.%assays%.%".imp"%.%i]
for (i in 1:n.imp) dat.mock.ph2["Delta"%.%assays%.%".imp"%.%i]=dat.mock.ph2["Day57"%.%assays%.%".imp"%.%i]-dat.mock.ph2["B"%.%assays%.%".imp"%.%i]


###########################################################################



```

```{r}
table(data$EventIndLongterm)
max(dat.mock[dat.mock$Trt==0 & dat.mock$Bserostatus==0 & dat.mock$Perprotocol==1, marker],na.rm=T)
```
```{r}

data <- dat.mock[dat.mock$Bserostatus==0 & dat.mock$Perprotocol==1,]
baseline <- c("MinorityInd", "HighRiskInd", "Age", "BRiskScore")
max_val <- max(dat.mock[dat.mock$Trt==0 & dat.mock$Bserostatus==0 & dat.mock$Perprotocol==1, marker],na.rm=T)

marker <- "Day57bindSpike"
weights = "wt"
outcome <- "EventIndLongterm"
data <- data[, c(outcome, marker, baseline, weights)]
data <- na.omit(data)
```


```{r}
data <- as.data.table(data)
node_list <- list(W = baseline,  A = marker, Y = outcome, weights =weights )

cutoffs <- quantile(data[,marker, with = F][[1]], c(0.7, 0.4))

thresholdTMLE(data, node_list, 4.12, NULL)


```


```{r}

library(data.table)
library(sl3)
data <- as.data.table(data)
get_task_list <- function(data, node_list, threshold_upper, threshold_lower = threshold_upper) {
  covariates <- node_list[["W"]]
  treatment <- node_list[["A"]]
  outcome <- node_list[["Y"]]
  weights <- node_list[["weights"]]
  data <- as.data.table(data)
  A <- data[[treatment]]
  if(!missing(threshold_lower)) {
    ind_lower <- as.numeric(A < threshold_lower)
  }
  if(!missing(threshold_upper)) {
    ind_upper <- as.numeric(A >= threshold_upper)
  }
  upper_var <- paste0(treatment, ">=", "u")
  lower_var <- paste0(treatment, "<", "l")
  data[[upper_var]] <- ind_upper
  data[[lower_var]] <- ind_lower
  print(data)
  cfu <- data.table::copy(data)
  cfl <- data.table::copy(data)
  cfu[[upper_var]] <- 1
  cfl[[lower_var]]  <- 1
  task_u_Y <- sl3_Task$new(data, covariates = c(covariates, upper_var), outcome = outcome, weights = weights )
  
  task_l_Y <- sl3_Task$new(data, covariates = c(covariates, lower_var), outcome = outcome, weights = weights )
  
  task_u_Y_cf <- sl3_Task$new(cfu, covariates = c(covariates, upper_var), outcome = outcome, weights = weights )
  
  task_l_Y_cf <- sl3_Task$new(cfl, covariates = c(covariates, lower_var), outcome = outcome, weights = weights )
  
  task_A_u <- sl3_Task$new(data, covariates = c(covariates), outcome = upper_var, weights = weights )
  task_A_l <- sl3_Task$new(data, covariates = c(covariates), outcome = lower_var, weights = weights )
  
  task_list <- list(data = data, Y = list(train_l = task_l_Y, train_u = task_u_Y, cfl = task_l_Y_cf, cfu = task_u_Y_cf), A = list(train_u = task_A_u, train_l = task_A_l))
  return(task_list)
}
print(weights)
node_list <- list(W = baseline,  A = marker, Y = outcome, weights =weights )
cutoffs <- quantile(data[,marker, with = F][[1]], c(0.7, 0.4))
task_list <- get_task_list(data, node_list, cutoffs[1], max_val + 0.2)



library(glmnet)
library(delayed)
library(sl3)
get_preds <- function(task_list, lrnr_A = NULL, lrnr_Y = NULL) {
  if(is.null(lrnr_A))  {
    lrnr_A <- Lrnr_glmnet$new()
  }
  if(is.null(lrnr_Y))  {
    lrnr_Y <- Lrnr_glmnet$new()
  }

  lrnr_A_l <- lrnr_A$train(task_list[["A"]][["train_l"]])
  lrnr_A_u <- lrnr_A$train(task_list[["A"]][["train_u"]])
  lrnr_Y_l <- lrnr_Y$train(task_list[["Y"]][["train_l"]])
  lrnr_Y_u <- lrnr_Y$train(task_list[["Y"]][["train_u"]])
  
  g1_l <- lrnr_A_l$predict(task_list[["A"]][["train_l"]])
  g1_u <- lrnr_A_u$predict(task_list[["A"]][["train_u"]])
  Q_l <- lrnr_Y_l$predict(task_list[["Y"]][["train_l"]])
  Q_u <- lrnr_Y_u$predict(task_list[["Y"]][["train_u"]])
  Q1_l <- lrnr_Y_l$predict(task_list[["Y"]][["cfl"]])
  Q1_u <- lrnr_Y_u$predict(task_list[["Y"]][["cfu"]])
  data.table(g1_l= g1_l, g1_u = g1_u, Q_l =  Q_l, Q_u = Q_u, Q1_l = Q1_l, Q1_u = Q1_u)
}

preds<-get_preds(task_list, Lrnr_glm$new(), Lrnr_glm$new())


do_update <- function(preds, task_list, node_list) {
  data <- task_list$data
  treatment <- node_list[["A"]]
  Y <- data[[node_list[["Y"]]]]

  if(!is.null(node_list[["weights"]])) {
    weights <- data[[node_list[["weights"]]]]
  } else{
    weights <- rep(1, nrow(data))
  }
  print(data.table(weights = weights))
  upper_var <- paste0(treatment, ">=", "u")
  lower_var <- paste0(treatment, "<", "l")
  H_l <- as.matrix(data[[lower_var]]/preds$g1_l)
  H_u <- as.matrix(data[[upper_var]]/preds$g1_u)
  print(data.table(H_l, H_u, Y))
  lst <- as.data.frame(list(H_l = H_l, Y = data[[node_list[["Y"]]]]))

  eps_l <- (coef(glm(Y ~ H_l - 1, offset =  qlogis(preds[["Q_l"]]), data = lst, family = binomial(), start = rep(0, ncol(H_l)), weights = weights)))
  eps_u <- suppressWarnings(coef(glm(Y ~ H_u - 1, offset =  qlogis(preds[["Q_u"]]), data = list(H_u = H_u, Y = data[[node_list[["Y"]]]]), family = binomial(), start = rep(0, ncol(H_l)), weights = weights)))
  print(c(eps_l, eps_u))
  Q1_l <- plogis( qlogis(preds[["Q1_l"]]) + eps_l/preds$g1_l )
  Q1_u <- plogis( qlogis(preds[["Q1_u"]]) + eps_u/preds$g1_u )
  Q_l <- as.vector(plogis( qlogis(preds[["Q_l"]]) + eps_l * H_l ))
  Q_u <- as.vector(plogis( qlogis(preds[["Q_u"]]) + eps_u * H_u))
  new_preds <- data.table(g1_l = preds$g1_l,  g1_u = preds$g1_u,Q_u = Q_u, Q_l = Q_l, Q1_l = Q1_l, Q1_u = Q1_u)
  IC_l <- H_l * (Y - new_preds$Q_l) * weights
  IC_u <- H_u * (Y - new_preds$Q_u) * weights
  psi_l <- weighted.mean(Q1_l, weights/sum(weights))
  psi_u <- weighted.mean(Q1_u, weights/sum(weights))

  estimates <- list(psi = c(psi_l, psi_u), IC = cbind(IC_l, IC_u) )
  
  return(estimates)
}

preds
estimates <- do_update(preds, task_list, node_list)


```

```{r}
weighted.mean(preds$Q1_l, data$wt / sum(data$wt))
weighted.mean(preds$Q1_u, data$wt / sum(data$wt))

estimates[[1]]
apply(estimates$IC,2,sd)/sqrt(nrow(data)) * 1.96
```


```{r}
psi_diff <- diff(estimates$psi)
radius <- 1.96 * sd(as.vector(estimates$IC[,2] - estimates$IC[,1])) / sqrt(nrow( estimates$IC))
c(psi_diff - radius,psi_diff,psi_diff + radius)



f_log_rr <- function(x, dx) {
  log(x[[2]]) - log(x[[1]])
}
df_log_rr <- function(x, dx) {
  dx[,2] / x[2] - dx[,1] / x[1]
}
rr_transform <- exp
delta_param_RR <- list(
  type = "RR",
  name = function(names) sprintf("RR(%s/%s)", names[[2]], names[[1]]),
  f = f_log_rr,
  df = df_log_rr,
  transform = rr_transform
)

x <- estimates$psi
x
dx <- estimates$IC

psi <- delta_param_RR$f(x, dx)
IC <- as.vector(delta_param_RR$df(x, dx))

radius <- 1.96 * sd(as.vector(IC))/sqrt(length(IC))
psi
radius
delta_param_RR$transform(c(psi - radius, psi, psi + radius))
```


```{r}

x[2]/x[1]

```
