---
title: "Practice dataset threshold-response function results"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}


```














```{r, include = F}
library(sl3)
library(tmleThresh)
library(tmle3)
markers <- c("Day57bindSpike" , "Day57bindRBD"  , "Day57pseudoneut" , "Day57liveneut" )
#devtools::install_github("Larsvanderlaan/tmle3", ref = "updating_updater")
```


```{r}
#load("dat.mock.rda")
#data <- read.csv("COVID_VEtrial_practicedata.csv")
#data
wts <- unique(dat.mock.vacc.seroneg$wt)
data <-dat.mock.vacc.seroneg

keep <- data$Trt==1 & data$Bserostatus==0 & data$Perprotocol==1
baseline <- c("MinorityInd", "HighRiskInd", "Age", "BRiskScore")
marker <- "Day57liveneut"

outcome <- "EventInd"
data <- data[keep, c(outcome, marker, baseline, "wt", "TwophasesampInd")]
data <- data.table(data)
table(data$wt)
data[, wtnew:= 1/mean(TwophasesampInd), by = wt]
data
data <- data.table(na.omit(data))
data
```


```{r, include = F}

wts <- unique(dat.mock.vacc.seroneg$wt)
data <-dat.mock.vacc.seroneg

keep <- data$Trt==1 & data$Bserostatus==0 & data$Perprotocol==1
baseline <- c("MinorityInd", "HighRiskInd", "Age", "BRiskScore")
marker <- "Day57pseudoneut"

outcome <- "EventInd"
data <- data[keep, c(outcome, marker, baseline, "wt", "TwophasesampInd")]
data <- data.table(data)
table(data$wt)
data[, wtnew:= 1/mean(TwophasesampInd), by = wt]
data
data <- data.table(na.omit(data))

#lrnr <- Lrnr_pooled_hazards$new(Lrnr_xgboost$new())
# To use machine learning
library(earth)
plot_data_list <- list()
choices <- c(0.05, 0.06, 0.07, 0.1,0.2, 0.3, 0.4,  0.5, 0.6,0.65, 0.7, 0.75, 0.8 , 0.85, 0.875, 0.9, 0.925, 0.95)
for(thresh in c(quantile(data[[marker]], choices))){
thresholds <- c(thresh)
print(thresholds)

lrnr_Y <- Lrnr_glmnet$new()
lrnr_A <-  Lrnr_glmnet$new()



tmle_spec <- tmle3_Spec_Threshold$new(method = "Psi_W", threshold_function = thresholds, cv = F)

learner_list <- list("A" = lrnr_A, "Y" =lrnr_Y)
node_list <- list("W" = baseline, "A" = marker, "Y" = outcome, "weights" = "wt")


tmle_task <- tmle_spec$make_tmle_task(data, node_list)
print("donef")
initial_likelihood <- tmle_spec$make_initial_likelihood(tmle_task, learner_list)
print("done")
updater <- tmle_spec$make_updater(maxit = 100, verbose = T)
targeted_likelihood <- tmle_spec$make_targeted_likelihood(initial_likelihood, updater)
print("k")
print(length(targeted_likelihood$get_likelihood(tmle_task, "Y")))
print("k")
print(length(targeted_likelihood$get_likelihood(tmle_task, "A")))
print("k")
tmle_params <- tmle_spec$make_params(tmle_task, targeted_likelihood)
print("done")
(targeted_likelihood$updater$update_step(targeted_likelihood, tmle_task))
print("done")
#Donvan estimator

weights <-1
get_estimates <- function(data, marker_var, outcome_var, thresholds, weights = rep(1, nrow(data))) {
  weights_unnorm <- weights
  weights <- weights/sum(weights)
  data <- as.data.table(data)
  IC_list <- list()
  est_list <- list()
  cdf_list <- c()
  for(thresh in thresholds) {
    meets_thresh <- as.numeric(data[[marker_var]] >= thresh) 
    cdf <- weighted.mean(meets_thresh, weights)
    cdf_list <- c(cdf_list, cdf)
    EY <- weighted.mean(data[[outcome_var]] * meets_thresh, weights) / cdf
    thresh <- as.character(thresh)
    est_list[[thresh]] <- EY
    IC_list[[thresh]] <- meets_thresh/cdf * (data[[outcome_var]] - EY) * weights_unnorm
    
  }
  return(list(est = unlist(est_list),
             IC = do.call(cbind, IC_list), cdf = 1-cdf_list ))
}
out <- get_estimates(data, marker, outcome, thresholds, weights = data$wt)
est <- out$est
IC <- out$IC * weights
radius <- 1.96 * sqrt(resample::colVars(IC))/sqrt(nrow(data))
lower <- est - radius
upper <- est + radius
donovan_est <- data.table(lower, est, upper )

estimates <- tmle_params[[1]]$estimates(tmle_task)
# This should be very small
# Estimates of Psi
estimates$psi

# Estimates and confidence bounds
sumry <- summary_from_estimates(tmle_task, list(estimates))[,-c(1,2,3)]
lower <- sumry$lower
upper <- sumry$upper
est <- sumry$tmle_est
cutoffs <- thresholds

cutoffs <- round(targeted_likelihood$factor_list$Y$learner$cutoffs,3)

plot_data <- data.frame(est = est, lower = lower, upper = upper, cutoffs = round(targeted_likelihood$factor_list$Y$learner$cutoffs,3))
plot_data2 <- donovan_est
plot_data2$cutoffs <- cutoffs
plot_data$grp <- "TMLE"
plot_data2$grp <- "Donovan"
plot_data <- rbind(plot_data, plot_data2)

plot_data_list <- c(plot_data_list, list(plot_data))

}
```




```{r, include = F}
library(ggplot2)
plot_data <- do.call(rbind, plot_data_list)
plot_data
 g1 <- ggplot2::ggplot(data =  plot_data, aes_string("cutoffs", "est", group = "grp", col="grp", fill="grp"))+ scale_x_continuous(breaks = plot_data$cutoffs) +
                              geom_line(aes_string(x = "cutoffs", y = "est",group = "grp", col="grp", fill="grp"), legend=  F) +
                              geom_point(aes_string(x = "cutoffs", y ="lower",group = "grp", col="grp", fill="grp"), legend=  F, alpha = 0) +
                              geom_point(aes_string(x = "cutoffs", y = "upper",group = "grp", col="grp", fill="grp"), legend=  F, alpha = 0) +
                            
                              geom_ribbon(aes(ymin = lower, ymax = upper), alpha= 0.2, color = NA) +
                              scale_x_continuous(breaks = plot_data$cutoffs)
 
```

```{r}
plot_data
g1 + xlab(paste0("Threshold value for ", marker)) + ylab("Threshold Resposne function")
```




```{r, include = F}

data <- read.csv("COVID_VEtrial_practicedata.csv")

keep <- data$Trt==1 & data$Bserostatus==0 & data$Perprotocol==1
baseline <- c("MinorityInd", "HighRiskInd", "Age", "BRiskScore")
marker <- "Day57bindRBD"

outcome <- "EventInd"
data <- data[keep, c(outcome, marker, baseline)]
data <- na.omit(data)
sum(is.na(data))

#lrnr <- Lrnr_pooled_hazards$new(Lrnr_xgboost$new())
# To use machine learning
library(earth)
plot_data_list <- list()
for(thresh in c(quantile(data[[marker]], c(0.05, 0.06, 0.07, 0.1,0.2, 0.3, 0.4,  0.5, 0.6,0.65, 0.7, 0.75, 0.8 , 0.85, 0.875, 0.9, 0.925, 0.95)))){
thresholds <- c(thresh)
print(thresholds)

lrnr_Y <- Lrnr_glmnet$new()
lrnr_A <-  Lrnr_glmnet$new()



tmle_spec <- tmle3_Spec_Threshold$new(method = "Psi_W", threshold_function = thresholds, cv = F)

learner_list <- list("A" = lrnr_A, "Y" =lrnr_Y)
node_list <- list("W" = baseline, "A" = marker, "Y" = outcome)


tmle_task <- tmle_spec$make_tmle_task(data, node_list)
print("donef")
initial_likelihood <- tmle_spec$make_initial_likelihood(tmle_task, learner_list)
print("done")
updater <- tmle_spec$make_updater(maxit = 100, verbose = T)
targeted_likelihood <- tmle_spec$make_targeted_likelihood(initial_likelihood, updater)
print("k")
print(length(targeted_likelihood$get_likelihood(tmle_task, "Y")))
print("k")
print(length(targeted_likelihood$get_likelihood(tmle_task, "A")))
print("k")
tmle_params <- tmle_spec$make_params(tmle_task, targeted_likelihood)
print("done")
(targeted_likelihood$updater$update_step(targeted_likelihood, tmle_task))
print("done")
#Donvan estimator

weights <-1
get_estimates <- function(data, marker_var, outcome_var, thresholds, weights = rep(1, nrow(data))) {
  weights <- weights/sum(weights)
  data <- as.data.table(data)
  IC_list <- list()
  est_list <- list()
  cdf_list <- c()
  for(thresh in thresholds) {
    meets_thresh <- as.numeric(data[[marker_var]] >= thresh) 
    cdf <- weighted.mean(meets_thresh, weights)
    cdf_list <- c(cdf_list, cdf)
    EY <- weighted.mean(data[[outcome_var]] * meets_thresh, weights) / cdf
    thresh <- as.character(thresh)
    est_list[[thresh]] <- EY
    IC_list[[thresh]] <- meets_thresh/cdf * (data[[outcome_var]] - EY)
    
  }
  return(list(est = unlist(est_list),
             IC = do.call(cbind, IC_list), cdf = 1-cdf_list ))
}
out <- get_estimates(data, marker, outcome, thresholds)
est <- out$est
IC <- out$IC * weights
radius <- 1.96 * sqrt(resample::colVars(IC))/sqrt(nrow(data))
lower <- est - radius
upper <- est + radius
donovan_est <- data.table(lower, est, upper )

estimates <- tmle_params[[1]]$estimates(tmle_task)
# This should be very small
# Estimates of Psi
estimates$psi

# Estimates and confidence bounds
sumry <- summary_from_estimates(tmle_task, list(estimates))[,-c(1,2,3)]
lower <- sumry$lower
upper <- sumry$upper
est <- sumry$tmle_est
cutoffs <- thresholds

cutoffs <- round(targeted_likelihood$factor_list$Y$learner$cutoffs,3)

plot_data <- data.frame(est = est, lower = lower, upper = upper, cutoffs = round(targeted_likelihood$factor_list$Y$learner$cutoffs,3))
plot_data2 <- donovan_est
plot_data2$cutoffs <- cutoffs
plot_data$grp <- "TMLE"
plot_data2$grp <- "Donovan"
plot_data <- rbind(plot_data, plot_data2)
print(plot_data)
plot_data_list <- c(plot_data_list, list(plot_data))

}
```





```{r, include = F}
library(ggplot2)
plot_data <- do.call(rbind, plot_data_list)
plot_data
 g1 <- ggplot2::ggplot(data =  plot_data, aes_string("cutoffs", "est", group = "grp", col="grp", fill="grp"))+ scale_x_continuous(breaks = plot_data$cutoffs) +
                              geom_line(aes_string(x = "cutoffs", y = "est",group = "grp", col="grp", fill="grp"), legend=  F) +
                              geom_point(aes_string(x = "cutoffs", y ="lower",group = "grp", col="grp", fill="grp"), legend=  F, alpha = 0) +
                              geom_point(aes_string(x = "cutoffs", y = "upper",group = "grp", col="grp", fill="grp"), legend=  F, alpha = 0) +
                            
                              geom_ribbon(aes(ymin = lower, ymax = upper), alpha= 0.2, color = NA) +
                              scale_x_continuous(breaks = plot_data$cutoffs)
 
```

```{r}
g1 + xlab(paste0("Threshold value for ", marker)) + ylab("Threshold Resposne function")
```





```{r, include = F}

data <- read.csv("COVID_VEtrial_practicedata.csv")

keep <- data$Trt==1 & data$Bserostatus==0 & data$Perprotocol==1
baseline <- c("MinorityInd", "HighRiskInd", "Age", "BRiskScore")
marker <- "Day57pseudoneut"

outcome <- "EventInd"
data <- data[keep, c(outcome, marker, baseline)]
data <- na.omit(data)
sum(is.na(data))

#lrnr <- Lrnr_pooled_hazards$new(Lrnr_xgboost$new())
# To use machine learning
library(earth)
plot_data_list <- list()
for(thresh in c(quantile(data[[marker]], c(0.05, 0.06, 0.07, 0.1,0.2, 0.3, 0.4,  0.5, 0.6,0.65, 0.7, 0.75, 0.8 , 0.85, 0.875, 0.9, 0.925, 0.95)))){
thresholds <- c(thresh)
print(thresholds)

lrnr_Y <- Lrnr_glmnet$new()
lrnr_A <-  Lrnr_glmnet$new()



tmle_spec <- tmle3_Spec_Threshold$new(method = "Psi_W", threshold_function = thresholds, cv = F)

learner_list <- list("A" = lrnr_A, "Y" =lrnr_Y)
node_list <- list("W" = baseline, "A" = marker, "Y" = outcome)


tmle_task <- tmle_spec$make_tmle_task(data, node_list)
print("donef")
initial_likelihood <- tmle_spec$make_initial_likelihood(tmle_task, learner_list)
print("done")
updater <- tmle_spec$make_updater(maxit = 100, verbose = T)
targeted_likelihood <- tmle_spec$make_targeted_likelihood(initial_likelihood, updater)
print("k")
print(length(targeted_likelihood$get_likelihood(tmle_task, "Y")))
print("k")
print(length(targeted_likelihood$get_likelihood(tmle_task, "A")))
print("k")
tmle_params <- tmle_spec$make_params(tmle_task, targeted_likelihood)
print("done")
(targeted_likelihood$updater$update_step(targeted_likelihood, tmle_task))
print("done")
#Donvan estimator

weights <-1
get_estimates <- function(data, marker_var, outcome_var, thresholds, weights = rep(1, nrow(data))) {
  weights <- weights/sum(weights)
  data <- as.data.table(data)
  IC_list <- list()
  est_list <- list()
  cdf_list <- c()
  for(thresh in thresholds) {
    meets_thresh <- as.numeric(data[[marker_var]] >= thresh) 
    cdf <- weighted.mean(meets_thresh, weights)
    cdf_list <- c(cdf_list, cdf)
    EY <- weighted.mean(data[[outcome_var]] * meets_thresh, weights) / cdf
    thresh <- as.character(thresh)
    est_list[[thresh]] <- EY
    IC_list[[thresh]] <- meets_thresh/cdf * (data[[outcome_var]] - EY)
    
  }
  return(list(est = unlist(est_list),
             IC = do.call(cbind, IC_list), cdf = 1-cdf_list ))
}
out <- get_estimates(data, marker, outcome, thresholds)
est <- out$est
IC <- out$IC * weights
radius <- 1.96 * sqrt(resample::colVars(IC))/sqrt(nrow(data))
lower <- est - radius
upper <- est + radius
donovan_est <- data.table(lower, est, upper )

estimates <- tmle_params[[1]]$estimates(tmle_task)
# This should be very small
# Estimates of Psi
estimates$psi

# Estimates and confidence bounds
sumry <- summary_from_estimates(tmle_task, list(estimates))[,-c(1,2,3)]
lower <- sumry$lower
upper <- sumry$upper
est <- sumry$tmle_est
cutoffs <- thresholds

cutoffs <- round(targeted_likelihood$factor_list$Y$learner$cutoffs,3)

plot_data <- data.frame(est = est, lower = lower, upper = upper, cutoffs = round(targeted_likelihood$factor_list$Y$learner$cutoffs,3))
plot_data2 <- donovan_est
plot_data2$cutoffs <- cutoffs
plot_data$grp <- "TMLE"
plot_data2$grp <- "Donovan"
plot_data <- rbind(plot_data, plot_data2)
print(plot_data)
plot_data_list <- c(plot_data_list, list(plot_data))

}
```





```{r, include = F}
library(ggplot2)
plot_data <- do.call(rbind, plot_data_list)
plot_data
 g1 <- ggplot2::ggplot(data =  plot_data, aes_string("cutoffs", "est", group = "grp", col="grp", fill="grp"))+ scale_x_continuous(breaks = plot_data$cutoffs) +
                              geom_line(aes_string(x = "cutoffs", y = "est",group = "grp", col="grp", fill="grp"), legend=  F) +
                              geom_point(aes_string(x = "cutoffs", y ="lower",group = "grp", col="grp", fill="grp"), legend=  F, alpha = 0) +
                              geom_point(aes_string(x = "cutoffs", y = "upper",group = "grp", col="grp", fill="grp"), legend=  F, alpha = 0) +
                            
                              geom_ribbon(aes(ymin = lower, ymax = upper), alpha= 0.2, color = NA) +
                              scale_x_continuous(breaks = plot_data$cutoffs)
 
```
 
```{r}
 
g1 + xlab(paste0("Threshold value for ", marker)) + ylab("Threshold Resposne function")
```





```{r, include = F}

data <- read.csv("COVID_VEtrial_practicedata.csv")

keep <- data$Trt==1 & data$Bserostatus==0 & data$Perprotocol==1
baseline <- c("MinorityInd", "HighRiskInd", "Age", "BRiskScore")
marker <- "Day57liveneut"

outcome <- "EventInd"
data <- data[keep, c(outcome, marker, baseline)]
data <- na.omit(data)
sum(is.na(data))

#lrnr <- Lrnr_pooled_hazards$new(Lrnr_xgboost$new())
# To use machine learning
library(earth)
plot_data_list <- list()
for(thresh in c(quantile(data[[marker]], c(0.05, 0.06, 0.07, 0.1,0.2, 0.3, 0.4,  0.5, 0.6,0.65, 0.7, 0.75, 0.8 , 0.85, 0.875, 0.9, 0.925, 0.95)))){
thresholds <- c(thresh)
print(thresholds)

lrnr_Y <- Lrnr_glmnet$new()
lrnr_A <-  Lrnr_glmnet$new()



tmle_spec <- tmle3_Spec_Threshold$new(method = "Psi_W", threshold_function = thresholds, cv = F)

learner_list <- list("A" = lrnr_A, "Y" =lrnr_Y)
node_list <- list("W" = baseline, "A" = marker, "Y" = outcome)


tmle_task <- tmle_spec$make_tmle_task(data, node_list)
print("donef")
initial_likelihood <- tmle_spec$make_initial_likelihood(tmle_task, learner_list)
print("done")
updater <- tmle_spec$make_updater(maxit = 100, verbose = T)
targeted_likelihood <- tmle_spec$make_targeted_likelihood(initial_likelihood, updater)
print("k")
print(length(targeted_likelihood$get_likelihood(tmle_task, "Y")))
print("k")
print(length(targeted_likelihood$get_likelihood(tmle_task, "A")))
print("k")
tmle_params <- tmle_spec$make_params(tmle_task, targeted_likelihood)
print("done")
(targeted_likelihood$updater$update_step(targeted_likelihood, tmle_task))
print("done")
#Donvan estimator

weights <-1
get_estimates <- function(data, marker_var, outcome_var, thresholds, weights = rep(1, nrow(data))) {
  weights <- weights/sum(weights)
  data <- as.data.table(data)
  IC_list <- list()
  est_list <- list()
  cdf_list <- c()
  for(thresh in thresholds) {
    meets_thresh <- as.numeric(data[[marker_var]] >= thresh) 
    cdf <- weighted.mean(meets_thresh, weights)
    cdf_list <- c(cdf_list, cdf)
    EY <- weighted.mean(data[[outcome_var]] * meets_thresh, weights) / cdf
    thresh <- as.character(thresh)
    est_list[[thresh]] <- EY
    IC_list[[thresh]] <- meets_thresh/cdf * (data[[outcome_var]] - EY)
    
  }
  return(list(est = unlist(est_list),
             IC = do.call(cbind, IC_list), cdf = 1-cdf_list ))
}
out <- get_estimates(data, marker, outcome, thresholds)
est <- out$est
IC <- out$IC * weights
radius <- 1.96 * sqrt(resample::colVars(IC))/sqrt(nrow(data))
lower <- est - radius
upper <- est + radius
donovan_est <- data.table(lower, est, upper )

estimates <- tmle_params[[1]]$estimates(tmle_task)
# This should be very small
# Estimates of Psi
estimates$psi

# Estimates and confidence bounds
sumry <- summary_from_estimates(tmle_task, list(estimates))[,-c(1,2,3)]
lower <- sumry$lower
upper <- sumry$upper
est <- sumry$tmle_est
cutoffs <- thresholds

cutoffs <- round(targeted_likelihood$factor_list$Y$learner$cutoffs,3)

plot_data <- data.frame(est = est, lower = lower, upper = upper, cutoffs = round(targeted_likelihood$factor_list$Y$learner$cutoffs,3))
plot_data2 <- donovan_est
plot_data2$cutoffs <- cutoffs
plot_data$grp <- "TMLE"
plot_data2$grp <- "Donovan"
plot_data <- rbind(plot_data, plot_data2)
print(plot_data)
plot_data_list <- c(plot_data_list, list(plot_data))

}
```





```{r, include = F}
library(ggplot2)
plot_data <- do.call(rbind, plot_data_list)
plot_data
 g1 <- ggplot2::ggplot(data =  plot_data, aes_string("cutoffs", "est", group = "grp", col="grp", fill="grp"))+ scale_x_continuous(breaks = plot_data$cutoffs) +
                              geom_line(aes_string(x = "cutoffs", y = "est",group = "grp", col="grp", fill="grp"), legend=  F) +
                              geom_point(aes_string(x = "cutoffs", y ="lower",group = "grp", col="grp", fill="grp"), legend=  F, alpha = 0) +
                              geom_point(aes_string(x = "cutoffs", y = "upper",group = "grp", col="grp", fill="grp"), legend=  F, alpha = 0) +
                            
                              geom_ribbon(aes(ymin = lower, ymax = upper), alpha= 0.2, color = NA) +
                              scale_x_continuous(breaks = plot_data$cutoffs)
 
```
```{r}
g1 + xlab(paste0("Threshold value for ", marker)) + ylab("Threshold Resposne function")
```
