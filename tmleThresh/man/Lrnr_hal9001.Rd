% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Learners.R
\docType{class}
\name{Lrnr_hal9001}
\alias{Lrnr_hal9001}
\title{The Scalable Highly Adaptive Lasso}
\format{
\code{\link{R6Class}} object.
}
\value{
Learner object with methods for training and prediction. See
 \code{\link{Lrnr_base}} for documentation on learners.
}
\description{
The Highly Adaptive Lasso is an estimation procedure that generates a design
 matrix consisting of basis functions corresponding to covariates and
 interactions of covariates and fits Lasso regression to this (usually) very
 wide matrix, recovering a nonparametric functional form that describes the
 target prediction function as a composition of subset functions with finite
 variation norm. This implementation uses \pkg{hal9001}, which provides both
 a custom implementation (based on \pkg{origami}) of the cross-validated
 lasso as well the standard call to \code{\link[glmnet]{cv.glmnet}} from the
 \pkg{glmnet}.
}
\section{Parameters}{

\describe{
  \item{\code{max_degree=3}}{ The highest order of interaction
   terms for which the basis functions ought to be generated. The default
   corresponds to generating basis functions up to all 3-way interactions of
   covariates in the input matrix, matching the default in \pkg{hal9001}.
  }
  \item{\code{fit_type="glmnet"}}{The specific routine to be called when
   fitting the Lasso regression in a cross-validated manner. Choosing the
   \code{"glmnet"} option calls either \code{\link[glmnet]{cv.glmnet}} or
   \code{\link[glmnet]{glmnet}}.
  }
  \item{\code{n_folds=10}}{Integer for the number of folds to be used
   when splitting the data for cross-validation. This defaults to 10 as this
   is the convention for V-fold cross-validation.
  }
  \item{\code{use_min=TRUE}}{Determines which lambda is selected from
   \code{\link[glmnet]{cv.glmnet}}. \code{TRUE} corresponds to
   \code{"lambda.min"} and \code{FALSE} corresponds to \code{"lambda.1se"}.
  }
  \item{\code{reduce_basis=NULL}}{A \code{numeric} value bounded in the open
   interval (0,1) indicating the minimum proportion of ones in a basis
   function column needed for the basis function to be included in the
   procedure to fit the Lasso. Any basis functions with a lower proportion
   of 1's than the specified cutoff will be removed. This argument defaults
   to \code{NULL}, in which case all basis functions are used in the Lasso
   stage of HAL.
  }
  \item{\code{return_lasso=TRUE}}{A \code{logical} indicating whether or not
   to return the \code{\link[glmnet]{glmnet}} fit of the Lasso model.
  }
  \item{\code{return_x_basis=FALSE}}{A \code{logical} indicating whether or
   not to return the matrix of (possibly reduced) basis functions used in
   the HAL Lasso fit.
  }
  \item{\code{basis_list=NULL}}{The full set of basis functions generated
   from the input data (from \code{\link[hal9001]{enumerate_basis}}). The
   dimensionality of this structure is roughly (n * 2^(d - 1)), where n is
   the number of observations and d is the number of columns in the input.
  }
  \item{\code{cv_select=TRUE}}{A \code{logical} specifying whether the array
   of values specified should be passed to \code{\link[glmnet]{cv.glmnet}}
   in order to pick the optimal value (based on cross-validation) (when set
   to \code{TRUE}) or to fit along the sequence of values (or a single value
   using \code{\link[glmnet]{glmnet}} (when set to \code{FALSE}).
  }
  \item{\code{...}}{Other parameters passed directly to
   \code{\link[hal9001]{fit_hal}}. See its documentation for details.
  }
}
}

\seealso{
Other Learners: 
\code{\link{Lrnr_cv}},
\code{\link{Lrnr_xgboost}}
}
\concept{Learners}
\keyword{data}
\section{Super class}{
\code{\link[sl3:Lrnr_base]{sl3::Lrnr_base}} -> \code{Lrnr_hal9001}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{Lrnr_hal9001$new()}}
\item \href{#method-clone}{\code{Lrnr_hal9001$clone()}}
}
}
\if{html}{
\out{<details ><summary>Inherited methods</summary>}
\itemize{
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="assert_trained">}\href{../../sl3/html/Lrnr_base.html#method-assert_trained}{\code{sl3::Lrnr_base$assert_trained()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="base_chain">}\href{../../sl3/html/Lrnr_base.html#method-base_chain}{\code{sl3::Lrnr_base$base_chain()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="base_predict">}\href{../../sl3/html/Lrnr_base.html#method-base_predict}{\code{sl3::Lrnr_base$base_predict()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="base_train">}\href{../../sl3/html/Lrnr_base.html#method-base_train}{\code{sl3::Lrnr_base$base_train()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="chain">}\href{../../sl3/html/Lrnr_base.html#method-chain}{\code{sl3::Lrnr_base$chain()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="custom_chain">}\href{../../sl3/html/Lrnr_base.html#method-custom_chain}{\code{sl3::Lrnr_base$custom_chain()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="get_outcome_range">}\href{../../sl3/html/Lrnr_base.html#method-get_outcome_range}{\code{sl3::Lrnr_base$get_outcome_range()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="get_outcome_type">}\href{../../sl3/html/Lrnr_base.html#method-get_outcome_type}{\code{sl3::Lrnr_base$get_outcome_type()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="predict">}\href{../../sl3/html/Lrnr_base.html#method-predict}{\code{sl3::Lrnr_base$predict()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="predict_fold">}\href{../../sl3/html/Lrnr_base.html#method-predict_fold}{\code{sl3::Lrnr_base$predict_fold()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="print">}\href{../../sl3/html/Lrnr_base.html#method-print}{\code{sl3::Lrnr_base$print()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="sample">}\href{../../sl3/html/Lrnr_base.html#method-sample}{\code{sl3::Lrnr_base$sample()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="set_train">}\href{../../sl3/html/Lrnr_base.html#method-set_train}{\code{sl3::Lrnr_base$set_train()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="subset_covariates">}\href{../../sl3/html/Lrnr_base.html#method-subset_covariates}{\code{sl3::Lrnr_base$subset_covariates()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="train">}\href{../../sl3/html/Lrnr_base.html#method-train}{\code{sl3::Lrnr_base$train()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="sl3" data-topic="Lrnr_base" data-id="train_sublearners">}\href{../../sl3/html/Lrnr_base.html#method-train_sublearners}{\code{sl3::Lrnr_base$train_sublearners()}}\out{</span>}
}
\out{</details>}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Lrnr_hal9001$new(
  max_degree = 2,
  num_bins = 30,
  fit_type = "glmnet",
  n_folds = 10,
  use_min = TRUE,
  reduce_basis = NULL,
  return_lasso = TRUE,
  return_x_basis = FALSE,
  basis_list = NULL,
  cv_select = TRUE,
  ...
)}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Lrnr_hal9001$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
