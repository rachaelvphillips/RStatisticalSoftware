
```{r, include=F}
#remotes::install_github("Larsvanderlaan/tmle3", ref = "devel")


devtools::document()
```
```{r}
setkey(data, id ,t)
key(data[, c("t", "id"), with = F])
```

```{r}

f = list("aa"= list("a" = "a"))
g = list("bb" = list("b" = "b" ))
c(g, (f))
```

```{r}
library(data.table)

# Generate simple causal model
library(simcausal)

D <- DAG.empty()
D <- D +
  node("W", distr = "runif", min =-1, max = 1) +
  node("A", distr = "rbinom", size = 1, prob = 0.5 + W/4 ) +
  node("T", distr = "rexp", rate = 0.05*(1 + 0.5*A - 0.3*W) )+
  node("C", distr = "rexp",  rate = 0.03*(1 + 0.4*A - 0.2*W)) +
  node("Delta", distr = "rconst", const = as.numeric(T<=C)  ) +
  node("Ttilde", distr = "rconst", const = round(min(T,C,10) +1  ))
setD <- set.DAG(D)
dat <- sim(setD, n = 1e3)
# only grab ID, W's, A, T.tilde, Delta
Lname <- grep("W", colnames(dat), value = TRUE)
Aname <- grep("A", colnames(dat), value = TRUE)
df <- dat[, c("ID", Lname, Aname, "T", "C", "Delta", "Ttilde")]

data <- df[,c( "W", "A", "Ttilde", "Delta")]
data$id = df$ID

data$t <- data$Ttilde 
data = data.table(data)
data$processA = as.numeric(data$Delta ==0)
data$processN = as.numeric(data$Delta ==1)
data_baseline <- data
data_baseline$t =0
data_baseline$processA = 0
data_baseline$processN = 0
data_baseline$Ttilde = NA
data_baseline$Delta = NA
data = rbind(data_baseline, data)
data$Ttilde = NULL
data$Delta = NULL
data$at_risk = 1 - (data$processA + data$processN)
data[which(data$processN==1), "processA"] = 0
npsem = list(define_lnode("W", c("W"), time =0), 
     define_lnode("A", c("A"), c("W"), time =0, summary_functions = make_summary_measure_baseline(c("W"))),
     
     define_lnode("processA", c("processA"),  c("A","W"), time = "pooled",times_to_pool = seq(1,max(data$t)), summary_functions = make_summary_measure_baseline(c("A", "W")),
                  at_risk_map = make_summary_measure_last_value("at_risk", strict_past  = T)),
     
define_lnode("processN", c("processN"), c("A","W"),time = "pooled",times_to_pool = seq(1,max(data$t)), summary_functions = make_summary_measure_baseline(c("A", "W")),
                  at_risk_map = make_summary_measure_last_value("at_risk", strict_past = T)))
# Delta is the counting process which is 1 at death
```

```{r}
test<-data
test
setkey(test, "id", "t")
key(test)
(test[1:100, c("t", "id", "A"), with = F])

```

```{r}
t = proc.time()
for(i in 1:1000){
 l= test[, last(.SD), by = id]
}
proc.time() - t

setkey(test, "t", "id")
t = proc.time()
for(i in 1:1000){
 v= test[!duplicated(test$id, fromLast = T, nmax = 10000),]
 setkey(v, "id", "t")
}
l
v
proc.time() - t
```

```{r}
library(dplyr)
data[, slice_tail(.SD), by = id]

```

```{r}
key(rbind(task$data, task$data))

```

```{r}
dat <- data[,]
setkey(dat, "id", "t")
dat
dats <- dat[1, c("id", "t", "processN")]
dats$processN =1
dats$id = 0
dat
f=dat[1]
f[rep(1,100)]
```



```{r}
task = ltmle3_Task$new(data, npsem )
key(task$data)
task$get_tmle_node("processN", include_time = T, expand = T, force_time_value = 5)
task$get_regression_task("processN" , expand = T)$data

```






```{r}
tlik = Targeted_Likelihood_pooled$new(lik, updater = tmle3_Update$new(one_dimensional = T,constrain_step=T, delta_epsilon = 0.1, maxit = 100))
param <- Param_survival$new(tlik, intervention_list = list("A" = LF_static$new("A", value = 1)), outcome_node = "processN")
param$get_EIC_var(task)
```


```{r}

param <- Param_survival$new(tlik, intervention_list = list(), outcome_node = "processN")

#subdata<- tlik$updater$generate_submodel_data(tlik, task, update_node_key = "processN")



```




```{r}

tlik$updater$update(tlik, task)
```

```{r}
tlik$get_likelihood(task, "processN")
lik$get_likelihood(task, "processN")
```


```{r}
lik$get_likelihood(task, "processN")
tlik$get_likelihood(task, "processN")
```


```{r}
 eps = tlik$updater$fit_submodel(subdata)
coef(eps)
preds<- predict(eps, type = "response")
obs <- subdata$observed[[1]]
mean(subdata$loss(preds,obs))
mean(subdata$loss(subdata$initial[[1]],obs))
data.table(subdata$H[[1]])
data.table(cbind(preds, subdata$initial[[1]],subdata$observed[[1]]))
data.table(cbind(task$get_regression_task("processN", drop_censored = T)$data[,processN],preds, subdata$observed[[1]]))
```

```{r}
sub <- tlik$updater$fit_submodel(subdata)
dim(sub$H)
H <- unlist(sub$H, use.names = F)

obs <- sub$observed
init <- sub$initial
 data.table(sub$H)
data.table(obs)
data.table(init)

 fit = glm(observed ~ H - 1, sub,
                                offset = qlogis(init),
                                family = binomial(),
                                start = rep(0, 1))
coef(fit)

```



```{r}

 # Generate simple causal model
 library(simcausal)
n=10000
 D <- DAG.empty()
 D <- D +
   node("W", distr = "rbinom", size = 1, prob = 0.5 )  +
   node("A", distr = "rbinom", size = 1, prob = 0.5 + W/4 ) +
     node("L1", distr = "rbinom", size = 1, prob = 0.5 + A/4 ) + 
     node("A1", distr = "rbinom", size = 1, prob = 0.5 + L1/4 ) +
     node("L2", distr = "rbinom", size = 1, prob = 0.5 + A1/4 ) + 
     node("A2", distr = "rbinom", size = 1, prob = 0.5 + L2/4 ) +
     node("L3", distr = "rbinom", size = 1, prob = 0.5 + A2/4 ) + 
     node("A3", distr = "rbinom", size = 1, prob = 0.5 + L3/4 ) +
     node("L4", distr = "rbinom", size = 1, prob = 0.5 + A3/4 ) + 
     node("A4", distr = "rbinom", size = 1, prob = 0.5 + L4/4 ) +
   node("Y", distr = "rbinom", size = 1, prob = 0.5 + A4/4 )
  
 setD <- set.DAG(D)
 dat <- sim(setD, n = n)
dat
L=unlist(dat[,stringr::str_detect(colnames(dat), "[WL]")], use.names = F)
A=unlist(dat[,stringr::str_detect(colnames(dat), "[A]")], use.names = F)
Y = dat$Y
dat
```

```{r}
dat=data.table(id = rep(1:n, 5), L = L, A = A, Y = Y, 
           t = c(rep(0, n), rep(1, n),rep(2, n),rep(3, n),rep(4, n)))
```

```{r}
lrnr = Lrnr_glm$new()
factor_list = list(LF_emp$new("W"),
LF_fit_pooled$new("A", lrnr),
LF_fit_pooled$new(c("A1", "A2", "A3", "A4"),lrnr),
LF_fit_pooled$new(c("L1", "L2", "L3", "L4"),lrnr),
LF_fit_pooled$new("Y",lrnr))
npsem = list(define_lnode("W", "L", c(), time = 0),
     define_lnode("A", "A", c("W"), time = 0),
     define_lnode("L1", "L", c("A"), time = 1),
      define_lnode("L2", "L", c("A1"), time = 2),
      define_lnode("L3", "L", c("A2"), time = 3),
      define_lnode("L4", "L", c("A3"), time = 4),
      define_lnode("A1", "A", c("L1"), time = 1),
      define_lnode("A2", "A", c("L2"), time = 2),
      define_lnode("A3", "A", c("L3"), time = 3),
      define_lnode("A4", "A", c("L4"), time = 4),
     define_lnode("Y", "Y", c("A4"), time = 4)
     
     
     
     )
lik = Likelihood_pooled$new(factor_list)
```

```{r}
matrix(list(as.vector(c(1,2)), as.vector(c(2,3))))
```
```{r}
task = ltmle3_Task$new(dat, npsem, extra_summary_measure_columns = NULL, thin =F)
t=proc.time()
f=task$get_regression_task("Y")
#lik_tr = lik$train(task)
#lik_tr$get_likelihoods(task)
t-proc.time()
sr = Sampler$new(lik_tr, c("W", "A", "L1", "A1",  "L2", "A2" , "L3", "A3" , "L4", "A4", "Y"), "W")

```













